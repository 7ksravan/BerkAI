## Complex Feature Engineering Greatly Improves Used Car Price Prediction

![image]([https://github.com/7ksravan/BerkAI/blob/main/images/17%20term%20deposit.jpg](https://github.com/7ksravan/BerkAI/blob/main/images/capimage.jpg))

## Summary

Spectacularly interesting results emerge after complex feature engineering the features of Used Car Prices dataset.

    1. Modeling with the newly engineered features demonstrate 20% reduction in RMSE error compared to modeling with the original features in the dataset. There is a remarkable ~50% reduction in Random Forest RMSE error. Linear Regression Model's RMSE error, training and test accuracy all show an ~30% improvement. Random Forest Test Accuracy shot up to 90%!
    2. What also standsout is the fact that a whole different set of features emerge as the most important ones driving price prediction. Engineered Features like State Purchasing Parity (externally sourced) & Model numerical value stole the show.
    3. Quite some interesting work went into applying extracting information from 'messy' model feature with NLP and in referencing external data for numerical transformation of existing features.
    
## Links
[Jupyter Notebook](https://github.com/7ksravan/BerkAI/blob/main/BerkAI_Customer_information_predicts_bank_marketing_success.ipynb)

## Project Hypothesis

My hypothesis is new features engineering will have a significant impact on improving the predictive abilities of both regression and classification models. The idea is to start with a a huge data set with complex numerical and categorical features where the model performance is not good to begin with. I will use the features in the dataset to engineer new features by applying a range of techniques from Natural Language Processing to Numerical Transformations. The baseline performance of multiple Machine Learn modeling on pre-feature-engineeded data will be compared against the model performance on the pre-feature-engineeded data to prove my hypothesis. 

## Motivation

Feature Engineering is a realm of creativity: literally sitting on the data and incubuating thoughts. This will be an opportunity to improve and learn in the area of feature engineering, researching and trying diverse techniques.

## Problem Statement

The **Business Objectives** is 2 folds:

1) how to optimize the banking campaign strategy to maximize client response
   
2) Which target customer groups are more likely to respond to the campaign and end up making a Term Deposit

The **Machine Learning objective** is:

to find the best classifier among the 4 specified classifier that have the best accuracy, precision, recall & F1 scores 

## Data

Dataset: USA Used Car Price prediction data set that contain ~420K records of user car sales price information.

Problem type: Regression

Target variable: PRICE

Features include:
1. Car make, model, manufacturer, YEAR of manufacture
2. Car specifications: ODOMETER reading, type, VIN, cyclinder, transmission, fuel type
3. Car status: title, condition
4. State and Region of sale

(upper case: numeric)

## ML Methodology

### Data Preparation

 1. Data Preparation:
    * SIR curation (sorting, irrelevant column removal, renaming) for columns
    * DON curation (duplicates, outliers, nulls) for row
    * **50% of raw data was lost in removing duplicates, outliers, null**
    * special issues: data type conversion to integer year and odometer

2. Exploratory Data Analysis:
    * Descriptive Statistics: numerical and categorical features visualizations, distributions
    * Inferential Statistics: features impact on y, features relation among them

3. Metrics for Regression Evaluation:
   *  RMSE: Root Mean Square Error (RMSE): an interpretable error number
   *  Training Accuracy: helps reveal overfitting, especially for tree models
   *  Test Accuracy: in some ways, the real measure of model performance for regression models
  
4. Models used in this project:
     * Linear Regression
     * K-Nearest Neighbor
     * Decision Tree Regressor
     * Gradient Boost Regressor
5. Techniques used for Feature Engineering:
     * Natural Language Processing: to extract information from the 'messy' model feature
     * Automobile domain-specific python modules: to extract information from VIN number
     * External data-referencing to transform features: US Bureau of labor data for State's purchasing parity to transform state feature
     * Target Encoding: on top of model values generated by NLP
     * Other: Binning, categorical-to-numerical mapping

